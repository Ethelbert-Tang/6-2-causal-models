{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences in Differences\n",
    "\n",
    "The basic setup to get a causal inference is the [Differences-in-Differences](https://en.wikipedia.org/wiki/Difference_in_differences) (DiD) setup, which measures before and after on a treatment and control group:\n",
    "\n",
    "![](diffindiff.png)\n",
    "\n",
    "The effect size here is $P_2 - Q$.\n",
    "\n",
    "This can be estimated by calculating the means and standard deviations of the 4 points (and testing them statistically), or by regression (the regression equation is in the wikipedia page). Regression modelling lets you add controls, which is useful.\n",
    "\n",
    "### AB Test\n",
    "\n",
    "It's most common in industry to exploit this setup by creating a control and test group of users for a new feature.\n",
    "\n",
    "Say you want a new front page on your website. The way to test *scientifically* is to send the new page to a certain % of users and measure the change in behavior against the rest using the old web page.\n",
    "\n",
    "**Random Assignment**\n",
    "\n",
    "Is paramount.\n",
    "\n",
    "If the selection criteria for the group you fall into (test, control) is correlated with the result of the test, the test will be invalid.\n",
    "\n",
    "### Natural Experiments\n",
    "\n",
    "It's often hard (or illegal!) to set up an A/B test in the real world. In this case it's common to try exploit a [\"Natural Experiment\"](https://en.wikipedia.org/wiki/Natural_experiment#Recent_examples) -- a change in the world that can be studied as if it was an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Control Group\n",
    "\n",
    "The [Synthetic Control](https://matheusfacure.github.io/python-causality-handbook/15-Synthetic-Control.html) method, which we've briefly seen in **workshop 5.5** uses a forecast to create a pseudo-control group.\n",
    "\n",
    "This can be useful if a major change is enacted and we don't have the opportunity of setting up an A/B test\n",
    "\n",
    "![](synthetic_control.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Discontinuity Design\n",
    "\n",
    "One way to bypass the requirement of a control group is by measuring an instantaneous effect. We've seen this in **workshop 3.4**.\n",
    "\n",
    "If there is a jump in a value at a certain point, we can measure the size of the jump and this can be interpreted as a **local, causal effect**.\n",
    "\n",
    "![](rdd1.png)\n",
    "\n",
    "There are [many examples of discontinuities](http://danluu.com/discontinuities/) out there, which can be exploited using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Scoring\n",
    "\n",
    "This can also be seen [here](https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html).\n",
    "\n",
    "One way to correct for **non random assignment** is to do a **two stage model** with weights for likelihood of being assigned a group.\n",
    "\n",
    "This is similar to the \"Hurdle model\" we used to correct for excessive 0 values in the Y variable.\n",
    "\n",
    "### Stage 1\n",
    "\n",
    "We train a logistic regression prediction 1 (if in the test group) or 0 (if in the control group) given all other features we're using.\n",
    "\n",
    "This is a model predicting \"group likelihood\" probabilities.\n",
    "\n",
    "### Stage 2\n",
    "\n",
    "We use the predicted probabilities as **weights** in the regression model. \n",
    "\n",
    "This can be done with [WLS](https://www.statsmodels.org/v0.11.1/examples/notebooks/generated/wls.html) in statsmodels or by using the `weights` parameter in the `fit` method in any SKLearn model.\n",
    "\n",
    "### Correcting for bias in a dataset\n",
    "\n",
    "This can be used to correct for bias by missing Y values in a dataset. The Movies Dataset is an example of this (around half the rows are missing a Y value for budget or revenue)\n",
    "\n",
    "You first train a model to predict wether the Y value being present or not given other model features.\n",
    "\n",
    "Then, you use these values to weigh by $(1 - Pr(missing))$ the model when doing the regression in the second stage -- to correct for data that is likely to be missing. As such, we overweigh \"unlikely\" data to pick up these correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}